import asyncio
import re
import os
import argparse
import json
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from pyppeteer import launch, errors
from pyppeteer.page import Page


class GovSpiderConfig:
    """æ”¿åºœç½‘ç«™çˆ¬è™«é…ç½®ç±»"""
    BASE_URL = "https://sousuo.www.gov.cn/sousuo/search.shtml"
    SEARCH_PARAMS = {
        "code": "17da70961a7",
        "dataTypeId": "107",
        "searchWord": "å›½åŠ¡é™¢åŠå…¬å…å…³äº{}å¹´éƒ¨åˆ†èŠ‚å‡æ—¥å®‰æ’çš„é€šçŸ¥"
    }
    SELECTORS = {
        "result_container": ".basic_result_content>.item",
        "result_item": ".basic_result_content>.item.is-news",
        "title_link": "a.title",
        "content_container": ".pages_content"
    }
    REQUEST_HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
    }
    TIMEOUTS = {
        "page_load": 60000,
        "element_wait": 30000,
        "content_load": 15000
    }

class GovHolidaySpider:
    """å›½åŠ¡é™¢èŠ‚å‡æ—¥å®‰æ’çˆ¬è™«"""

    def __init__(self, debug: bool = True):
        self.debug = debug
        self.config = GovSpiderConfig()
        self.crawler = HolidayCrawler(debug)

    async def _log(self, message: str, icon: str = "ğŸ”"):
        """è®°å½•æ—¥å¿—"""
        if self.debug:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"{icon} [{timestamp}] {message}")

    async def _init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨å®ä¾‹"""
        await self._log("å¯åŠ¨æ— å¤´æµè§ˆå™¨...", "ğŸš€")
        return await launch(
            headless=True,
            args=['--no-sandbox', '--disable-setuid-sandbox']
        )

    async def _process_search_page(self, page: Page, year: int) -> List[Dict]:
        """å¤„ç†æœç´¢ç»“æœé¡µé¢"""
        search_word = self.config.SEARCH_PARAMS["searchWord"].format(year)
        url_params = {
            "code": self.config.SEARCH_PARAMS["code"],
            "dataTypeId": self.config.SEARCH_PARAMS["dataTypeId"],
            "searchWord": search_word
        }
        search_url = f"{self.config.BASE_URL}?{'&'.join(f'{k}={v}' for k,v in url_params.items())}"

        await self._log(f"æœç´¢ {year}å¹´èŠ‚å‡æ—¥å®‰æ’ â†’ {search_url}", "ğŸŒ")
        try:
            response = await page.goto(search_url, {
                'waitUntil': 'networkidle2',
                'timeout': self.config.TIMEOUTS["page_load"]
            })
            if not response.ok:
                await self._log(f"é¡µé¢åŠ è½½å¤±è´¥ HTTP {response.status}", "âŒ")
                return []
        except errors.NetworkError as e:
            await self._log(f"ç½‘ç»œé”™è¯¯: {str(e)}", "âš ï¸")
            return []
        except errors.TimeoutError:
            await self._log("é¡µé¢åŠ è½½è¶…æ—¶", "â³")
            return []

        return await self._parse_search_results(page, year)

    async def _parse_search_results(self, page: Page, year: int) -> List[Dict]:
        """è§£ææœç´¢ç»“æœ"""
        await self._log("ç­‰å¾…ç»“æœåŠ è½½...", "â³")
        try:
            await page.waitForSelector(
                self.config.SELECTORS["result_container"],
                {'timeout': self.config.TIMEOUTS["element_wait"]}
            )
        except errors.TimeoutError:
            await self._log("ç»“æœåŠ è½½è¶…æ—¶", "â³")
            return []

        items = await page.querySelectorAll(self.config.SELECTORS["result_item"])
        await self._log(f"å‘ç° {len(items)} æ¡æœç´¢ç»“æœ", "ğŸ“Š")

        results = []
        for idx, item in enumerate(items, 1):
            result = await self._process_result_item(item, page, year, idx)
            if result:
                results.append(result)
        return results

    async def _process_result_item(self, item, page: Page, year: int, idx: int) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªæœç´¢ç»“æœé¡¹"""
        await self._log(f"è§£æç¬¬ {idx} æ¡ç»“æœ", "ğŸ“„")

        try:
            title_element = await item.querySelector(self.config.SELECTORS["title_link"])
            if not title_element:
                await self._log("æ ‡é¢˜å…ƒç´ ç¼ºå¤±", "âš ï¸")
                return None

            title = await page.evaluate('(e) => e.textContent.trim()', title_element)
            link = await page.evaluate('(e) => e.href', title_element)

            content = await self._fetch_detail_content(link)
            parsed_data = self.crawler.parse(content, year)

            return {
                'year': year,
                'title': title,
                'link': link,
                'content': content,
                'parsed_data': parsed_data['holidays'],
                'publish_date': parsed_data['metadata']['publish_date']
            }
        except Exception as e:
            await self._log(f"å¤„ç†å¤±è´¥: {str(e)}", "âŒ")
            return None

    async def _fetch_detail_content(self, url: str) -> str:
        """è·å–è¯¦æƒ…é¡µå†…å®¹"""
        await self._log(f"è®¿é—®è¯¦æƒ…é¡µ â†’ {url}", "ğŸ”—")
        detail_page = await self.browser.newPage()

        try:
            await detail_page.setUserAgent(self.config.REQUEST_HEADERS["User-Agent"])
            await detail_page.goto(url, {
                'waitUntil': 'domcontentloaded',
                'timeout': self.config.TIMEOUTS["page_load"]
            })

            try:
                await detail_page.waitForSelector(
                    self.config.SELECTORS["content_container"],
                    {'timeout': self.config.TIMEOUTS["content_load"]}
                )
            except errors.TimeoutError:
                await self._log("å†…å®¹åŠ è½½è¶…æ—¶", "â³")

            return await detail_page.evaluate('''() => {
                const el = document.querySelector('.pages_content');
                return el ? el.innerText.trim() : 'CONTENT_NOT_FOUND';
            }''')
        except errors.NetworkError:
            return 'NETWORK_ERROR'
        finally:
            await detail_page.close()

    async def run(self, years: List[int]) -> Dict[int, List[Dict]]:
        """æ‰§è¡Œçˆ¬è™«ä»»åŠ¡"""
        self.browser = await self._init_browser()
        results = {}

        try:
            for year in years:
                page = await self.browser.newPage()
                await page.setUserAgent(self.config.REQUEST_HEADERS["User-Agent"])
                year_results = await self._process_search_page(page, year)
                results[year] = year_results
                await page.close()
        finally:
            await self.browser.close()

        return results

class HolidayCrawler:
    """èŠ‚å‡æ—¥é€šçŸ¥è§£æå™¨"""

    def __init__(self, debug: bool = True):
        self.debug = debug

    def _log(self, message: str, icon: str = "ğŸ›"):
        """è°ƒè¯•æ—¥å¿—"""
        if self.debug:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"{icon} [{timestamp}] {message}")

    def parse(self, text: str, year: int) -> dict:
        """è§£æå¹´åº¦é€šçŸ¥æ ¸å¿ƒå†…å®¹"""
        self._log(f"å¼€å§‹è§£æ {year}å¹´èŠ‚å‡æ—¥é€šçŸ¥", "ğŸ”")
        result = {}

        # å‡æ—¥æ­£åˆ™è¡¨è¾¾å¼
        holiday_pattern = re.compile(
            r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ã€\s*'       # åŒ¹é…åºå·
            r'([^ï¼š:\n]+?)\s*'                     # åŒ¹é…èŠ‚æ—¥åç§°éƒ¨åˆ†
            r'[ï¼š:]\s*'                            # åŒ¹é…åˆ†éš”ç¬¦
            r'((?:.(?!\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€))*.)',  # åŒ¹é…å†…å®¹(ä½¿ç”¨å¦å®šå‰ç»)
            re.DOTALL
        )

        # æ—¥æœŸèŒƒå›´æ­£åˆ™ï¼Œæ”¯æŒå¹´ä»½å’Œç®€å†™æ ¼å¼
        date_range_pattern = re.compile(
            r'((?:\d{4}å¹´)?\d{1,2}æœˆ\d{1,2}æ—¥)\D*è‡³\D*'  # å¼€å§‹æ—¥æœŸ
            r'((?:\d{4}å¹´)?(?:\d{1,2}æœˆ\d{1,2}æ—¥|\d{1,2}æ—¥))'  # ç»“æŸæ—¥æœŸ
        )

        # è¡¥ç­æ—¥æœŸåŒ¹é…æ¨¡å¼ï¼ˆæ”¯æŒå¤šä¸ªæ—¥æœŸåˆ†éš”ï¼‰
        workday_pattern = re.compile(
            r'((?:\d{1,2}æœˆ\d{1,2}æ—¥\s*(?:ï¼ˆ[^ï¼‰]*ï¼‰)?\s*[,ã€]?\s*)+)ä¸Šç­'  # åŒ¹é…è¿ç»­æ—¥æœŸ
        )

        # éå†æ‰€æœ‰èŠ‚å‡æ—¥æ¡ç›®
        for match in holiday_pattern.finditer(text):
            self._log(f"å‘ç°ç¬¬{match.group(1)}æ¡èŠ‚å‡æ—¥æ¡ç›®", "ğŸ“Œ")
            _, name_part, content = match.groups()

            # å¤„ç†å¤šèŠ‚æ—¥æƒ…å†µ(æ”¯æŒä¸­æ–‡é¡¿å·ã€å’Œ)
            names = re.split(r'[ã€å’Œ]', name_part.strip())
            self._log(f"åŸå§‹èŠ‚æ—¥åç§°: {name_part} â†’ æ‹†åˆ†ç»“æœ: {names}", "âœ¨")

            # è§£ææ—¥æœŸèŒƒå›´
            date_range = date_range_pattern.search(content)
            holiday_data = {}
            date_list = []

            # å¤„ç†æ—¥æœŸèŒƒå›´
            if date_range:
                self._log(f"æ‰¾åˆ°æ—¥æœŸèŒƒå›´: {date_range.group()}", "ğŸ“…")
                start_str, end_str = date_range.groups()

                start_date = self._parse_date(start_str, year)
                self._log(f"è§£æå¼€å§‹æ—¥æœŸ: {start_str} â†’ {start_date}", "â±ï¸" if start_date else "âš ï¸")

                end_date = self._parse_end_date(end_str, start_date, year)
                self._log(f"è§£æç»“æŸæ—¥æœŸ: {end_str} â†’ {end_date}", "â±ï¸" if end_date else "âš ï¸")

                if start_date and end_date:
                    # å¤„ç†è·¨å¹´é€»è¾‘
                    if end_date < start_date:
                        self._log("æ£€æµ‹åˆ°è·¨å¹´æ—¥æœŸï¼Œè‡ªåŠ¨ä¿®æ­£å¹´ä»½", "ğŸ”„")
                        end_date = end_date.replace(year=end_date.year + 1)
                    date_list = self._generate_date_range(start_date, end_date)
                    self._log(f"ç”Ÿæˆæ—¥æœŸèŒƒå›´: {len(date_list)}å¤© ({date_list[0]} ~ {date_list[-1]})", "ğŸ“†")
                    holiday_data['dates'] = date_list
            else:
                self._log("æœªæ‰¾åˆ°æ—¥æœŸèŒƒå›´ï¼Œå°è¯•åŒ¹é…å•æ—¥æœŸ", "ğŸ”")
                # å¤„ç†å•æ—¥æœŸ
                single_date_pattern = re.compile(r'(\d{1,2}æœˆ\d{1,2}æ—¥)[^è‡³]*$')
                single_date = single_date_pattern.search(content)
                if single_date:
                    start_date = self._parse_date(single_date.group(1), year)
                    if start_date:
                        # å¤„ç†è·¨å¹´å•æ—¥æœŸï¼ˆå¦‚12æœˆ31æ—¥è·¨å¹´ï¼‰
                        if start_date.year != year:
                            start_date = start_date.replace(year=year)
                        date_list = [start_date]
                        holiday_data['dates'] = date_list

            # æå–è¡¥ç­æ—¥æœŸï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
            work_days = []
            if date_match := workday_pattern.search(content):
                self._log(f"æ‰¾åˆ°è¡¥ç­æ—¥æœŸ: {date_match.group(1)}", "ğŸ‘”")
                date_strings = re.findall(r'\d{1,2}æœˆ\d{1,2}æ—¥', date_match.group(1))
                for date_str in date_strings:
                    parsed_date = self._parse_date(date_str, year)
                    status_icon = "âœ…" if parsed_date else "âŒ"
                    self._log(f"è§£æè¡¥ç­æ—¥æœŸ: {date_str} â†’ {parsed_date}", status_icon)
                    if parsed_date:
                        work_days.append(parsed_date)

            # è¿‡æ»¤æ— æ•ˆè¡¥ç­æ—¥æœŸ
            if work_days:
                valid_work_days = []
                date_range_start = date_list[0] if date_list else None
                date_range_end = date_list[-1] if date_list else None

                for wd in work_days:
                    # æ’é™¤åœ¨æ”¾å‡æ—¥æœŸèŒƒå›´å†…çš„è¡¥ç­æ—¥æœŸ
                    if date_range_start and date_range_end:
                        if not (date_range_start <= wd <= date_range_end):
                            valid_work_days.append(wd)
                    else:
                        valid_work_days.append(wd)
                self._log(f"è¿‡æ»¤åæœ‰æ•ˆè¡¥ç­æ—¥æœŸ: {len(valid_work_days)}ä¸ª", "ğŸ›¡ï¸")
                holiday_data['work_days'] = valid_work_days

            # åˆå¹¶ç»“æœ
            for name in names:
                name = name.strip()
                if not name:
                    continue

                # è‡ªåŠ¨è¡¥å…¨å¸¸è§èŠ‚æ—¥åç§°
                original_name = name
                if 'èŠ‚' not in name:
                    if name in ['å…ƒæ—¦', 'åŠ³åŠ¨', 'å›½åº†']:
                        name += 'èŠ‚'
                    elif name in ['æ¸…æ˜', 'ç«¯åˆ', 'ä¸­ç§‹']:
                        name += 'èŠ‚'
                if original_name != name:
                    self._log(f"è‡ªåŠ¨è¡¥å…¨èŠ‚æ—¥åç§°: {original_name} â†’ {name}", "ğŸ·ï¸")
                result[name] = holiday_data.copy()

        # ç‹¬ç«‹æ£€æŸ¥æ—¥æœŸèŒƒå›´ç›¸åŒçš„èŠ‚æ—¥ï¼Œå¹¶è¿›è¡Œåˆå¹¶
        self._log("å¼€å§‹åˆå¹¶ç›¸åŒæ—¥æœŸçš„èŠ‚æ—¥", "ğŸ”„")
        date_to_names = {}  # ç”¨äºå­˜å‚¨æ—¥æœŸèŒƒå›´å¯¹åº”çš„èŠ‚æ—¥åç§°
        for name, info in result.items():
            dates = tuple(info.get('dates', []))  # å°†æ—¥æœŸåˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„
            if dates not in date_to_names:
                date_to_names[dates] = []
            date_to_names[dates].append(name)

        # åˆå¹¶æ—¥æœŸèŒƒå›´ç›¸åŒçš„èŠ‚æ—¥
        final_result = {
            'holidays': {},  # ç‹¬ç«‹å­˜å‚¨èŠ‚å‡æ—¥ä¿¡æ¯
            'metadata': {}   # å­˜å‚¨å…ƒæ•°æ®
        }
        for dates, names in date_to_names.items():
            if len(names) > 1:
                # å¦‚æœæœ‰å¤šä¸ªèŠ‚æ—¥æ—¥æœŸèŒƒå›´ç›¸åŒï¼Œåˆå¹¶ä¸ºä¸€ä¸ªæ¡ç›®
                combined_name = 'ã€'.join(names)
                self._log(f"åˆå¹¶ç›¸åŒæ—¥æœŸèŠ‚æ—¥: {names} â†’ {combined_name}", "âœ¨")
                final_result['holidays'][combined_name] = result[names[0]]
            else:
                # å¦åˆ™ç›´æ¥æ·»åŠ åˆ°æœ€ç»ˆç»“æœ
                final_result['holidays'][names[0]] = result[names[0]]

        # å…ƒæ•°æ®è§£æ
        publish_date = self._parse_publish_date(text)
        if publish_date:
            final_result['metadata']['publish_date'] = publish_date
            self._log(f"è§£æåˆ°å‘æ–‡æ—¥æœŸ: {publish_date.strftime('%Y-%m-%d')}", "ğŸ“")

        self._log(f"è§£æå®Œæˆï¼Œå…±æ‰¾åˆ°{len(final_result['holidays'])}ä¸ªèŠ‚å‡æ—¥", "ğŸ‰")
        return final_result

    def _parse_date(self, date_str: str, year: int) -> datetime:
        """æ¸…æ´—å¹¶è½¬æ¢æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ”¯æŒè·¨å¹´æ—¥æœŸ"""
        try:
            clean_date = re.sub(r'[ï¼ˆ(].*?[)ï¼‰]', '', date_str).strip()
            match = re.match(r'(?:(\d{4})å¹´)?(\d{1,2})æœˆ(\d{1,2})æ—¥', clean_date)
            if not match:
                return None
            y, m, d = match.groups()
            # å¦‚æœæ—¥æœŸä¸­åŒ…å«å¹´ä»½ï¼Œåˆ™ä½¿ç”¨è¯¥å¹´ä»½ï¼›å¦åˆ™ä½¿ç”¨ä¼ å…¥çš„é»˜è®¤å¹´ä»½
            year = int(y) if y else year
            month = m.zfill(2)
            day = d.zfill(2)
            return datetime.strptime(f"{year}-{month}-{day}", "%Y-%m-%d")
        except Exception as e:
            self._log(f"æ—¥æœŸè§£æå¤±è´¥: {date_str} - {str(e)}")
            return None

    def _parse_end_date(self, end_str: str, start_date: datetime, default_year: int) -> datetime:
        """è§£æå¯èƒ½ç®€å†™çš„ç»“æŸæ—¥æœŸ"""
        # å°è¯•å®Œæ•´è§£æ
        parsed = self._parse_date(end_str, default_year)
        if parsed:
            return parsed

        # å¤„ç†ä»…æ—¥æƒ…å†µï¼ˆå¦‚"27æ—¥"ï¼‰
        day_match = re.match(r'(\d{1,2})æ—¥', end_str)
        if day_match and start_date:
            try:
                day = int(day_match.group(1))
                # å¤„ç†è·¨æœˆæƒ…å†µ
                parsed = start_date.replace(day=day)
                if parsed < start_date:
                    # å¦‚æœç»“æŸæ—¥æœŸå°äºå¼€å§‹æ—¥æœŸï¼Œåˆ™è®¤ä¸ºæ˜¯è·¨æœˆ
                    next_month = start_date.replace(day=28) + timedelta(days=4)  # è·³åˆ°ä¸‹ä¸ªæœˆ
                    parsed = next_month.replace(day=day)
                return parsed
            except Exception as e:
                self._log(f"ç»“æŸæ—¥æœŸè§£æå¤±è´¥ {end_str}: {e}")
        return None

    def _generate_date_range(self, start: datetime, end: datetime) -> list:
        """ç”Ÿæˆè¿ç»­æ—¥æœŸåºåˆ—"""
        return [start + timedelta(days=x) for x in range((end - start).days + 1)]

    # å‘æ–‡æ—¥æœŸè§£ææ–¹æ³•
    def _parse_publish_date(self, text: str) -> datetime:
        """è§£æå‘æ–‡æ—¥æœŸ"""
        publish_date_pattern = re.compile(
            r'å›½åŠ¡é™¢åŠå…¬å…\s*'          # åŒ¹é…å‘æ–‡æœºæ„
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',  # æ•è·å‘æ–‡æ—¥æœŸ
            re.MULTILINE
        )

        if match := publish_date_pattern.search(text):
            return self._parse_date(match.group(1), datetime.now().year)
        return None


async def main(args):
    """ä¸»è¿è¡Œå‡½æ•°"""
    spider = GovHolidaySpider(debug=not args.quiet)

    # æ˜¾ç¤ºå¯åŠ¨æ¨ªå¹…
    if not args.quiet:
        print("\n" + "="*40)
        print("ğŸ¯ å›½åŠ¡é™¢èŠ‚å‡æ—¥å®‰æ’æŠ“å–å·¥å…·".center(38))
        print("="*40)
        print(f"ğŸ“… ç›®æ ‡å¹´ä»½: {', '.join(map(str, args.years))}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {os.path.abspath(args.output)}")
        print("="*40 + "\n")

    # æ‰§è¡Œçˆ¬å–
    results = await spider.run(args.years)

    # ä¿å­˜ç»“æœ
    os.makedirs(args.output, exist_ok=True)
    for year, data in results.items():
        filename = f"holidays_{year}.json"
        save_path = os.path.join(args.output, filename)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)

    return results

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""

    parser = argparse.ArgumentParser(
        description="å›½åŠ¡é™¢èŠ‚å‡æ—¥å®‰æ’æŠ“å–å·¥å…·",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument('-o', '--output',
                        default='output',
                        help='è¾“å‡ºæ–‡ä»¶ç›®å½•')
    parser.add_argument('-y', '--years',
                        nargs='+',
                        type=int,
                        required=not ('ipykernel' in sys.modules),
                        help='è¦æŠ“å–çš„å¹´ä»½åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰')
    parser.add_argument('-q', '--quiet',
                        action='store_true',
                        help='é™é»˜æ¨¡å¼')
    return parser.parse_args()

if __name__ == "__main__":
    # Windowsç³»ç»Ÿéœ€è¦è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    args = parse_args()

    # éªŒè¯å¹´ä»½æœ‰æ•ˆæ€§
    if args:
        current_year = datetime.now().year
        for y in args.years:
            if not (2000 <= y <= current_year + 2):
                print(f"âš ï¸  æ— æ•ˆå¹´ä»½: {y} (ä»…æ”¯æŒ2000-{current_year + 2}å¹´)")
                exit(1)

    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main(args if args else None))